{"ast":null,"code":"'use strict';\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nvar _templateObject;\n\nfunction _createForOfIteratorHelper(o, allowArrayLike) { var it; if (typeof Symbol === \"undefined\" || o[Symbol.iterator] == null) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; var F = function F() {}; return { s: F, n: function n() { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function e(_e) { throw _e; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var normalCompletion = true, didErr = false, err; return { s: function s() { it = o[Symbol.iterator](); }, n: function n() { var step = it.next(); normalCompletion = step.done; return step; }, e: function e(_e2) { didErr = true; err = _e2; }, f: function f() { try { if (!normalCompletion && it[\"return\"] != null) it[\"return\"](); } finally { if (didErr) throw err; } } }; }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _taggedTemplateLiteral(strings, raw) { if (!raw) { raw = strings.slice(0); } return Object.freeze(Object.defineProperties(strings, { raw: { value: Object.freeze(raw) } })); }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _wrapNativeSuper(Class) { var _cache = typeof Map === \"function\" ? new Map() : undefined; _wrapNativeSuper = function _wrapNativeSuper(Class) { if (Class === null || !_isNativeFunction(Class)) return Class; if (typeof Class !== \"function\") { throw new TypeError(\"Super expression must either be null or a function\"); } if (typeof _cache !== \"undefined\") { if (_cache.has(Class)) return _cache.get(Class); _cache.set(Class, Wrapper); } function Wrapper() { return _construct(Class, arguments, _getPrototypeOf(this).constructor); } Wrapper.prototype = Object.create(Class.prototype, { constructor: { value: Wrapper, enumerable: false, writable: true, configurable: true } }); return _setPrototypeOf(Wrapper, Class); }; return _wrapNativeSuper(Class); }\n\nfunction _construct(Parent, args, Class) { if (_isNativeReflectConstruct()) { _construct = Reflect.construct; } else { _construct = function _construct(Parent, args, Class) { var a = [null]; a.push.apply(a, args); var Constructor = Function.bind.apply(Parent, a); var instance = new Constructor(); if (Class) _setPrototypeOf(instance, Class.prototype); return instance; }; } return _construct.apply(null, arguments); }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _isNativeFunction(fn) { return Function.toString.call(fn).indexOf(\"[native code]\") !== -1; }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\nvar BB = require('bluebird');\n\nvar contentPath = require('./content/path');\n\nvar crypto = require('crypto');\n\nvar figgyPudding = require('figgy-pudding');\n\nvar fixOwner = require('./util/fix-owner');\n\nvar fs = require('graceful-fs');\n\nvar hashToSegments = require('./util/hash-to-segments');\n\nvar ms = require('mississippi');\n\nvar path = require('path');\n\nvar ssri = require('ssri');\n\nvar Y = require('./util/y.js');\n\nvar indexV = require('../package.json')['cache-version'].index;\n\nvar appendFileAsync = BB.promisify(fs.appendFile);\nvar readFileAsync = BB.promisify(fs.readFile);\nvar readdirAsync = BB.promisify(fs.readdir);\nvar concat = ms.concat;\nvar from = ms.from;\n\nmodule.exports.NotFoundError = /*#__PURE__*/function (_Error) {\n  _inherits(NotFoundError, _Error);\n\n  var _super = _createSuper(NotFoundError);\n\n  function NotFoundError(cache, key) {\n    var _this;\n\n    _classCallCheck(this, NotFoundError);\n\n    _this = _super.call(this, Y(_templateObject || (_templateObject = _taggedTemplateLiteral([\"No cache entry for `\", \"` found in `\", \"`\"], [\"No cache entry for \\\\`\", \"\\\\` found in \\\\`\", \"\\\\`\"])), key, cache));\n    _this.code = 'ENOENT';\n    _this.cache = cache;\n    _this.key = key;\n    return _this;\n  }\n\n  return NotFoundError;\n}( /*#__PURE__*/_wrapNativeSuper(Error));\n\nvar IndexOpts = figgyPudding({\n  metadata: {},\n  size: {}\n});\nmodule.exports.insert = insert;\n\nfunction insert(cache, key, integrity, opts) {\n  opts = IndexOpts(opts);\n  var bucket = bucketPath(cache, key);\n  var entry = {\n    key: key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size: opts.size,\n    metadata: opts.metadata\n  };\n  return fixOwner.mkdirfix(cache, path.dirname(bucket)).then(function () {\n    var stringified = JSON.stringify(entry); // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with this.\n\n    return appendFileAsync(bucket, \"\\n\".concat(hashEntry(stringified), \"\\t\").concat(stringified));\n  }).then(function () {\n    return fixOwner.chownr(cache, bucket);\n  })[\"catch\"]({\n    code: 'ENOENT'\n  }, function () {// There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }).then(function () {\n    return formatEntry(cache, entry);\n  });\n}\n\nmodule.exports.insert.sync = insertSync;\n\nfunction insertSync(cache, key, integrity, opts) {\n  opts = IndexOpts(opts);\n  var bucket = bucketPath(cache, key);\n  var entry = {\n    key: key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size: opts.size,\n    metadata: opts.metadata\n  };\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket));\n  var stringified = JSON.stringify(entry);\n  fs.appendFileSync(bucket, \"\\n\".concat(hashEntry(stringified), \"\\t\").concat(stringified));\n\n  try {\n    fixOwner.chownr.sync(cache, bucket);\n  } catch (err) {\n    if (err.code !== 'ENOENT') {\n      throw err;\n    }\n  }\n\n  return formatEntry(cache, entry);\n}\n\nmodule.exports.find = find;\n\nfunction find(cache, key) {\n  var bucket = bucketPath(cache, key);\n  return bucketEntries(bucket).then(function (entries) {\n    return entries.reduce(function (latest, next) {\n      if (next && next.key === key) {\n        return formatEntry(cache, next);\n      } else {\n        return latest;\n      }\n    }, null);\n  })[\"catch\"](function (err) {\n    if (err.code === 'ENOENT') {\n      return null;\n    } else {\n      throw err;\n    }\n  });\n}\n\nmodule.exports.find.sync = findSync;\n\nfunction findSync(cache, key) {\n  var bucket = bucketPath(cache, key);\n\n  try {\n    return bucketEntriesSync(bucket).reduce(function (latest, next) {\n      if (next && next.key === key) {\n        return formatEntry(cache, next);\n      } else {\n        return latest;\n      }\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null;\n    } else {\n      throw err;\n    }\n  }\n}\n\nmodule.exports[\"delete\"] = del;\n\nfunction del(cache, key, opts) {\n  return insert(cache, key, null, opts);\n}\n\nmodule.exports[\"delete\"].sync = delSync;\n\nfunction delSync(cache, key, opts) {\n  return insertSync(cache, key, null, opts);\n}\n\nmodule.exports.lsStream = lsStream;\n\nfunction lsStream(cache) {\n  var indexDir = bucketDir(cache);\n  var stream = from.obj(); // \"/cachename/*\"\n\n  readdirOrEmpty(indexDir).map(function (bucket) {\n    var bucketPath = path.join(indexDir, bucket); // \"/cachename/<bucket 0xFF>/*\"\n\n    return readdirOrEmpty(bucketPath).map(function (subbucket) {\n      var subbucketPath = path.join(bucketPath, subbucket); // \"/cachename/<bucket 0xFF>/<bucket 0xFF>/*\"\n\n      return readdirOrEmpty(subbucketPath).map(function (entry) {\n        var getKeyToEntry = bucketEntries(path.join(subbucketPath, entry)).reduce(function (acc, entry) {\n          acc.set(entry.key, entry);\n          return acc;\n        }, new Map());\n        return getKeyToEntry.then(function (reduced) {\n          var _iterator = _createForOfIteratorHelper(reduced.values()),\n              _step;\n\n          try {\n            for (_iterator.s(); !(_step = _iterator.n()).done;) {\n              var _entry = _step.value;\n              var formatted = formatEntry(cache, _entry);\n              formatted && stream.push(formatted);\n            }\n          } catch (err) {\n            _iterator.e(err);\n          } finally {\n            _iterator.f();\n          }\n        })[\"catch\"]({\n          code: 'ENOENT'\n        }, nop);\n      });\n    });\n  }).then(function () {\n    stream.push(null);\n  }, function (err) {\n    stream.emit('error', err);\n  });\n  return stream;\n}\n\nmodule.exports.ls = ls;\n\nfunction ls(cache) {\n  return BB.fromNode(function (cb) {\n    lsStream(cache).on('error', cb).pipe(concat(function (entries) {\n      cb(null, entries.reduce(function (acc, xs) {\n        acc[xs.key] = xs;\n        return acc;\n      }, {}));\n    }));\n  });\n}\n\nfunction bucketEntries(bucket, filter) {\n  return readFileAsync(bucket, 'utf8').then(function (data) {\n    return _bucketEntries(data, filter);\n  });\n}\n\nfunction bucketEntriesSync(bucket, filter) {\n  var data = fs.readFileSync(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\n\nfunction _bucketEntries(data, filter) {\n  var entries = [];\n  data.split('\\n').forEach(function (entry) {\n    if (!entry) {\n      return;\n    }\n\n    var pieces = entry.split('\\t');\n\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return;\n    }\n\n    var obj;\n\n    try {\n      obj = JSON.parse(pieces[1]);\n    } catch (e) {\n      // Entry is corrupted!\n      return;\n    }\n\n    if (obj) {\n      entries.push(obj);\n    }\n  });\n  return entries;\n}\n\nmodule.exports._bucketDir = bucketDir;\n\nfunction bucketDir(cache) {\n  return path.join(cache, \"index-v\".concat(indexV));\n}\n\nmodule.exports._bucketPath = bucketPath;\n\nfunction bucketPath(cache, key) {\n  var hashed = hashKey(key);\n  return path.join.apply(path, [bucketDir(cache)].concat(hashToSegments(hashed)));\n}\n\nmodule.exports._hashKey = hashKey;\n\nfunction hashKey(key) {\n  return hash(key, 'sha256');\n}\n\nmodule.exports._hashEntry = hashEntry;\n\nfunction hashEntry(str) {\n  return hash(str, 'sha1');\n}\n\nfunction hash(str, digest) {\n  return crypto.createHash(digest).update(str).digest('hex');\n}\n\nfunction formatEntry(cache, entry) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity) {\n    return null;\n  }\n\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: contentPath(cache, entry.integrity),\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata\n  };\n}\n\nfunction readdirOrEmpty(dir) {\n  return readdirAsync(dir)[\"catch\"]({\n    code: 'ENOENT'\n  }, function () {\n    return [];\n  })[\"catch\"]({\n    code: 'ENOTDIR'\n  }, function () {\n    return [];\n  });\n}\n\nfunction nop() {}","map":null,"metadata":{},"sourceType":"module"}